# Reuko-1B: Mini T5 Pipeline

Reuko-1B, T5 tabanlÄ± Question Answering (QA) ve Text Summarization gÃ¶revleri iÃ§in geliÅŸtirilmiÅŸ bir mini AI pipeline'dÄ±r.

## ğŸš€ Ã–zellikler

- **Question Answering**: SQuAD dataset ile eÄŸitilmiÅŸ QA modeli
- **Text Summarization**: CNN/DailyMail dataset ile Ã¶zetleme
- **HÄ±zlÄ± Prototipleme**: Mini dataset'ler ile hÄ±zlÄ± test
- **Kolay KullanÄ±m**: Jupyter notebook ile interaktif geliÅŸtirme

## ğŸ“‹ Gereksinimler

- Python 3.10+
- PyTorch 2.0+
- Transformers 4.30+
- CUDA (opsiyonel, GPU desteÄŸi iÃ§in)

## ğŸ› ï¸ Kurulum

1. **Repository'yi klonla:**
```bash
git clone <repo-url>
cd reuko-1B
```

2. **BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kle:**
```bash
pip install -r requirements.txt
```

3. **Notebook'u Ã§alÄ±ÅŸtÄ±r:**
```bash
jupyter notebook reuko_mini_pipeline.ipynb
```

## ğŸ“š KullanÄ±m

### HÄ±zlÄ± BaÅŸlangÄ±Ã§

1. `reuko_mini_pipeline.ipynb` dosyasÄ±nÄ± aÃ§
2. TÃ¼m hÃ¼creleri sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±r
3. Model otomatik olarak eÄŸitilir ve test edilir

### QA Ã–rneÄŸi

```python
question = "Who developed Python?"
context = "Python was created by Guido van Rossum in 1991."
answer = test_qa(question, context)
print(f"Answer: {answer}")
```

### Summarization Ã–rneÄŸi

```python
text = "Long article text here..."
summary = test_summarization(text)
print(f"Summary: {summary}")
```

## ğŸ¯ Model PerformansÄ±

- **Model**: T5-small (60M parametreler)
- **Training**: 2 epoch, mini dataset
- **HÄ±z**: ~5 saniye/batch (CPU)
- **Bellek**: ~2GB RAM

## ğŸ“ Proje YapÄ±sÄ±

```
reuko-1B/
â”œâ”€â”€ reuko_mini_pipeline.ipynb   # Ana notebook
â”œâ”€â”€ config.py                   # KonfigÃ¼rasyon
â”œâ”€â”€ utils.py                    # YardÄ±mcÄ± fonksiyonlar
â”œâ”€â”€ requirements.txt            # BaÄŸÄ±mlÄ±lÄ±klar
â”œâ”€â”€ setup.py                    # Kurulum scripti
â”œâ”€â”€ README.md                   # Bu dosya
â””â”€â”€ reuko_mini/                 # Model Ã§Ä±ktÄ±larÄ±
    â”œâ”€â”€ qa_model/              # QA modeli
    â””â”€â”€ summary_model/         # Summarization modeli
```

## âš™ï¸ KonfigÃ¼rasyon

`config.py` dosyasÄ±nda aÅŸaÄŸÄ±daki parametreleri deÄŸiÅŸtirebilirsiniz:

- `BATCH_SIZE`: Batch bÃ¼yÃ¼klÃ¼ÄŸÃ¼ (varsayÄ±lan: 4)
- `NUM_EPOCHS`: Epoch sayÄ±sÄ± (varsayÄ±lan: 2)
- `QA_TRAIN_SIZE`: QA training veri boyutu (varsayÄ±lan: 1000)
- `LEARNING_RATE`: Ã–ÄŸrenme oranÄ± (varsayÄ±lan: 5e-4)

## ğŸ”§ GeliÅŸtirme

### Yeni Veri Seti Ekleme

```python
from utils import ReukoUtils

utils = ReukoUtils(tokenizer)
processed_data = utils.preprocess_qa_batch(new_dataset)
```

### Model Ä°yileÅŸtirme

1. **Daha fazla veri**: `config.py`'da veri boyutlarÄ±nÄ± artÄ±r
2. **Daha uzun eÄŸitim**: `NUM_EPOCHS` deÄŸerini artÄ±r
3. **Daha bÃ¼yÃ¼k model**: `MODEL_NAME`'i `t5-base` olarak deÄŸiÅŸtir

## ğŸ“Š SonuÃ§lar

Notebook Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda:
- Training loss grafikleri gÃ¶sterilir
- QA Ã¶rnekleri test edilir
- Summarization Ã¶rnekleri test edilir
- Model performans metrikleri yazdÄ±rÄ±lÄ±r

## ğŸ¤ KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Add some AmazingFeature'`)
4. Branch'inizi push edin (`git push origin feature/amazing-feature`)
5. Pull Request aÃ§Ä±n

## ğŸ“„ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

## ğŸš€ Sonraki AdÄ±mlar

- [ ] Multi-task learning implementation
- [ ] ROUGE/BLEU evaluation metrics
- [ ] Model distillation for speed
- [ ] Web API deployment
- [ ] Docker containerization
- [ ] Gradio UI integration

## ğŸ“ Ä°letiÅŸim

- GitHub: [Reuko-1B](https://github.com/your-username/reuko-1B)
- Issues: [GitHub Issues](https://github.com/your-username/reuko-1B/issues)

---

Made with â¤ï¸ by Rei Calasso
